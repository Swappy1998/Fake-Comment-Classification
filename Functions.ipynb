{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "stop_words = set(stopwords.words('english'))\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn import metrics\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix\n",
    "import pickle\n",
    "\n",
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "punc = '''!()-[]{};:'\"\\,<>./?@#$%^&*_~'''\n",
    "def remove_p(test_str):\n",
    "    for ele in test_str:  \n",
    "        if ele in punc:  \n",
    "            test_str = test_str.replace(ele, \"\")\n",
    "    return test_str\n",
    "\n",
    "def remove_stopwords(input_str):\n",
    "    tokens = word_tokenize(input_str)\n",
    "    result = [str(i) for i in tokens if not i in stop_words]\n",
    "    return result\n",
    "\n",
    "\n",
    "def lemmatize(input_list):\n",
    "    temp_list = []\n",
    "    lemmatizer=WordNetLemmatizer()\n",
    "    for word in input_list:\n",
    "        temp_list.append(lemmatizer.lemmatize(word))\n",
    "    return(temp_list)\n",
    "\n",
    "def vectorizer(st):\n",
    "    filename = 'TfidfVectorizer.sav'\n",
    "    loaded_model = pickle.load(open(filename, 'rb'))\n",
    "    X = loaded_model.transform([st])\n",
    "    return(X)\n",
    "\n",
    "def svm_model(X):\n",
    "    filename = 'svm.sav'\n",
    "    model = pickle.load(open(filename, 'rb'))\n",
    "    predicted_labels = model.predict(X)\n",
    "    print(predicted_labels[0])\n",
    "    if predicted_labels == 1:\n",
    "        return('Advertisement')\n",
    "    else:\n",
    "        return('No Advertisement')\n",
    "    \n",
    "    \n",
    "def classify(st):\n",
    "    st = st.lower()\n",
    "    print\n",
    "    st = remove_p(st)\n",
    "    print(st)\n",
    "    st = remove_stopwords(st)\n",
    "    print(st)\n",
    "    st = lemmatize(st)\n",
    "    print(st)\n",
    "    st = ' '.join(st)\n",
    "    print(st)\n",
    "    X = vectorizer(st)\n",
    "    print(X)\n",
    "    X = X.toarray()\n",
    "#     predicted_label = svm_model(X)\n",
    "    print(predicted_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nsadjdkl naskldnaklsnd 123 sankldasn \n",
      "['nsadjdkl', 'naskldnaklsnd', '123', 'sankldasn']\n",
      "['nsadjdkl', 'naskldnaklsnd', '123', 'sankldasn']\n",
      "nsadjdkl naskldnaklsnd 123 sankldasn\n",
      "  (0, 2366)\t0.05948318313785085\n",
      "  (0, 3201)\t0.081934699544153\n",
      "  (0, 3207)\t0.12053567646831495\n",
      "  (0, 3405)\t0.049053195721821534\n",
      "  (0, 3409)\t0.12586523601013014\n",
      "  (0, 3414)\t0.18826794254053653\n",
      "  (0, 4067)\t0.08779976714327953\n",
      "  (0, 4281)\t0.09038665903149995\n",
      "  (0, 4484)\t0.08569241491019258\n",
      "  (0, 4659)\t0.056191873257810256\n",
      "  (0, 4735)\t0.10201973187727216\n",
      "  (0, 4951)\t0.1240607133029336\n",
      "  (0, 4989)\t0.17022951501555847\n",
      "  (0, 4992)\t0.17771613886644805\n",
      "  (0, 6394)\t0.11160142509759165\n",
      "  (0, 6395)\t0.06261614756702842\n",
      "  (0, 6571)\t0.09131068331428581\n",
      "  (0, 6832)\t0.17022951501555847\n",
      "  (0, 6868)\t0.1395562563992763\n",
      "  (0, 11107)\t0.09226872830776635\n",
      "  (0, 11216)\t0.09834764585832023\n",
      "  (0, 11519)\t0.40621773177780096\n",
      "  (0, 11520)\t0.3187653361023312\n",
      "  (0, 11633)\t0.08373093108163317\n",
      "  (0, 11634)\t0.06547396414219786\n",
      "  (0, 11714)\t0.1395562563992763\n",
      "  (0, 11715)\t0.18826794254053653\n",
      "  (0, 11874)\t0.14911867919637817\n",
      "  (0, 11906)\t0.17022951501555847\n",
      "  (0, 12321)\t0.11611423244062433\n",
      "  (0, 12338)\t0.18826794254053653\n",
      "  (0, 13240)\t0.10052549577264569\n",
      "  (0, 13394)\t0.15006629372857153\n",
      "  (0, 13436)\t0.17771613886644805\n",
      "  (0, 13493)\t0.08374579188579725\n",
      "  (0, 13494)\t0.09767232474144026\n",
      "  (0, 13845)\t0.09226872830776635\n",
      "  (0, 14020)\t0.1103071558327444\n",
      "  (0, 14025)\t0.16442243840767853\n",
      "  (0, 17272)\t0.08979187451969566\n",
      "  (0, 17403)\t0.17606146366923237\n",
      "  (0, 17416)\t0.16442243840767853\n",
      "  (0, 17432)\t0.1439036635351082\n",
      "  (0, 17742)\t0.13257496784257947\n",
      "  (0, 17806)\t0.22714019798537677\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'predicted_label' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-5c8e1029b4e2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mclassify\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"nsadjdkl naskldnaklsnd 123 sankldasn \"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-8-e27f9a144dfb>\u001b[0m in \u001b[0;36mclassify\u001b[1;34m(st)\u001b[0m\n\u001b[0;32m     51\u001b[0m     \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[1;31m#     predicted_label = svm_model(X)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 53\u001b[1;33m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredicted_label\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'predicted_label' is not defined"
     ]
    }
   ],
   "source": [
    "classify(\"nsadjdkl naskldnaklsnd 123 sankldasn \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
